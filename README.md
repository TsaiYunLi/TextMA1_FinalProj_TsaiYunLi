# TextMA1_FinalProj_TsaiYunLi
In an imaged scenario, I am working for a media buying company, Chrishare, whose goal is to help their new client, Theragun, to conduct contextual advertising by placing Theragun's ads on web pages of news about wellness, since Theragun have already found out that those who value wellness are their potential customers.
<br>

As an NLP engineer in the company, my task is to build a deep learning algorithm to predict the probability that a news story is about wellness. I have got a labelled training dataset (see section 2 for details), so a supervised machine learning approach suits this task. Since my company gives me limited computational resources, I will use the k-train library, a lightweight wrapper for Tensorflow, Keras, and Huggingface Transformers, as well as the transformer model "distillbert," which inherited the training regime and architecture from BERT in a a distilled version, striking a balance between speed and performance, to process the text data and train my final models. To tell to what degree of contextual information is necessary, I will train two models: model1, a DistilBERT-base-uncased transformer model with unigram only, and model2, a DistilBERT-base-uncased transformer model with bigram only. The two models will be evaluated in terms of their validation datasets' precision, recall, and f1-score for the positive class. Finally, the model with the best performance will be chosen to demo to our customer, Theragun.
<br>

Some Notes on the Models' Hyperparameters: <br>
Compared with the lab assignment we've done, the hyperparameters I tweaked in this project are maxlen, ngram_range, and the number of epochs during model training and fitting the best learning rate to the model (marked with a "#"). I used the 99% text length as the value for maxlen (see section 4 for visualizations and detailed explanation). I also experimented with the number of epochs for model training, starting from epoch=6, and found out that the elbow sweet point occured within 3 epochs. Therefore, to save run time, its epoch number is set to 3. As for the number of epochs for fitting the best learning rate, I cut it down to 3 to shorten the run time without any good reasoning (see more in limitations). The hyperparameters of the two models only differ in their ngram_rage. Model 1 uses unigrams only, with ngram_rage=(1,1); while, model 2 uses bigrams only, with ngram_rage=(2,2).
<br>

Model Performance Evaluation Results and Conclusion: <br>
Since our goal is to place Theragun's add in as many wellness news web page as possible and that a few misplacements would not do much harm, among all the metrics, we value 'recall' most. The model with a higher recall (0.95) for the positive class is model1, DistilBERT-base-uncased transformer model using unigrams only. Model2, which uses bigrams, probably introduced sparsity that lowered its recall a little bit (0.94). It turns out that unigram captures enough contextual information for the model. Nevertheless, the two models both perform pretty well, with very close precision, recall, and f1-score values on their validation sets. In conclusion, to pick out the best model for the task described in section 1, model 1, DistilBERT-base-uncased transformer model with unigram (positive class recall=0.95) is most suitable.
<br>

Limiataions: <br>
There are quite some limitations in this project. First of all, due to limited GPU avaliable in this free Google Colab, larger transformer models like BERT or RoBERTa and complexer libraries beside ktrain are hard to implement. The ktrain library also limit the choice of transformer model to 'standard,' 'bert,' and 'distilbert,' making distilRoBERTa-base unavailiable. It would be interesting to compare a distilRoBERTa-base solution to the distilBERT-base-uncased ones built in this project. Secondly, to avoid crazy long run time (run time for 3 epochs already took more than an hour), I had to cut the epoch number for learning-rate-fitting to 3, not waiting till an early stop before the models starting to overfit. This can potentially lower the performance of the models. These limitations could possibly be lifted if I had access to more computational resources, which could speed up model training run time.
<br>
Please kindly point out if there is anything I've done wrong or could improve in this project! Also, please do not copy my code or text without proper citation. Thank you!
